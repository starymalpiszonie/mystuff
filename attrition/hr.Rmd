---
title: "Employee attrition"
output: html_notebook
---


```{r}
library(data.table)
library(dplyr)
```

Read the data
```{r}
inp <- fread("../data/hr.csv")
```

Cleanup data
```{r}

inp$rand<-sample(1:10,nrow(inp),T)

train <- inp %>% filter(rand<=8) %>% select(-rand)


test <- inp %>% filter(rand>8) %>% select(-rand)
```

Build simple tree model

```{r}
library(rpart)

tree_model <- rpart(left~.,data=train,method = "class")
```

```{r}
library(rattle)
fancyRpartPlot(tree_model)
```

AUC on test
```{r}
pred <- predict(tree_model,test,type="prob")[,2]
library(pROC)

auc(test$left,pred)

```

Logistic regression

```{r}
lr_model <- glm(left ~.,family=binomial(link='logit'),data=train)
summary(lr_model)
```
```{r}
pred <- predict(lr_model,test,type="response")
auc(test$left,pred)
```

Random forest

Transform to binary variables
```{r}
categs <- inp %>% 
  select(sales,salary)

library(caret)
dummy <- dummyVars(" ~ .",categs)
binary.categs <- data.frame(predict(dummy, categs))

nums <- inp %>% select(-sales,-salary,-left)

inp.binary <- cbind(binary.categs,nums)

train.binary <- inp.binary[inp$rand<=8,]
test.binary <- inp.binary[inp$rand>8,]

train.binary$left <- train$left
test.binary$left <- test$left
train.binary$rand<-NULL
test.binary$rand<-NULL

```


Random forest
```{r}

library(ranger)
model.forest <- ranger(left ~ ., data = train.binary,num.trees = 500)
pred <- predict(model.forest,test.binary,type="response")
auc(test.binary$left,pred[["predictions"]])
```

GLM
```{r}
library(glmnet)
y.train <- train.binary$left
train.binary$left<-NULL

y.test <- test.binary$left
test.binary$left<-NULL

train.binary<-as.matrix(train.binary)
test.binary <- as.matrix(test.binary)

glmnet_classifier = cv.glmnet(x = train.binary, y = y.train, 
                              family = 'binomial', 
                              # L1 penalty
                              alpha = 1,
                              # interested in the area under ROC curve
                              type.measure = "auc",
                              # 5-fold cross-validation
                              nfolds = 5,
                              # high value is less accurate, but has faster training
                              thresh = 1e-3,
                              # again lower number of iterations for faster training
                              maxit = 1e5)

preds = predict(glmnet_classifier,test.binary, type = 'response')[,1]

auc(y.test,preds)

```

xgboost
```{r}
library(xgboost)

param <- list(objective = "binary:logistic",max_depth=6,colsample=1)


xgboost.cv = xgb.cv(param=param, data = train.binary,label = y.train, nfold = 10, nrounds = 1500, early_stopping_rounds = 100, metrics='auc')

best_iteration = xgboost.cv$best_iteration
xgb.model <- xgboost(param=param, data = train.binary,label = y.train,nrounds=best_iteration)

preds <- predict(xgb.model,test.binary,type="response")
auc(y.test,preds)
```
Explain xgboost
```{r}
importance <- xgb.importance(feature_names = colnames(train.binary), model = xgb.model)
head(importance)

to_explain <- as(as.matrix(test.binary[c(1,420),]),"dgCMatrix")
```
Explain negative (do not churn)
```{r}
e <- predict(xgb.model,to_explain,predcontrib = TRUE)
e[1,]

```

```{r}
contribution_plot<-function(explained_one, in_variable_cnt = 10){
  
  total <- sum(explained_one$contrib)
  total.df<-data.frame(
    variable=c("total"),
    result=total,
    abs_result=c(999),
    feature=c("total"),stringsAsFactors = F)
  
  cutoff <-explained_one$cutoff[1]
  cutoff_logit <- log(cutoff/(1-cutoff))
  
  #-- title line
  TARGET<-explained_one$code[1]
  score<-round(exp(total)/(1+exp(total)),3)
  rel<-ifelse(score>=cutoff,">=","<")
  title_line<-paste0("Code: ",TARGET," Score: ",score,rel,round(cutoff,3))
  
  #-- draw the plot
  explained_one %>%
    select(contrib,feature,feature_value) %>%
    mutate(
      variable=feature,
      feature=paste0(feature,"=",feature_value),
      abs_result=abs(contrib),
      result=contrib,
      feature=ifelse(variable=="BIAS","BIAS",feature)
    ) %>%
    select(variable, result,abs_result,feature) %>%
    union_all(total.df) %>%
    arrange(desc(abs_result)) %>%
    mutate(
      rnk=row_number(desc(abs_result)),
      fill_color=ifelse(variable=="total",ifelse(result>cutoff_logit,1,-1),ifelse(result>0,1,-1)),
      prob=round(exp(result)/(1+exp(result)),3)
    ) %>%
    filter(rnk<=in_variable_cnt+1) %>%
    ggplot(aes(x=reorder(feature,desc(rnk)),y=result,fill=factor(fill_color)))+
    geom_bar(stat="identity")+
    #geom_text(aes(label=prob),vjust=0)+
    coord_flip() +
    xlab("feature")+
    ylab("log-likelihood")+
    geom_hline(yintercept=cutoff_logit)+
    scale_fill_manual(name="Decision",
                      breaks=c(-1, 1),
                      labels=c("Contradicts","Supports"),
                      values=c("tomato1","dodgerblue3"))+
    ggtitle(title_line)
  
}
```

```{r}

exp_to_df <- function(wh){
  explained <- data.frame(e[wh,]) 
  explained$feature <- row.names(explained)
  explained$feature_value <- c(to_explain[wh,],NA)
  colnames(explained) <- c("contrib","feature","feature_value")
  explained$cutoff<-0.5
  explained
}

negative_case <- exp_to_df(1)
positive_case <- exp_to_df(2)

```
```{r}
contribution_plot(negative_case)
```

```{r}
contribution_plot(positive_case)
```


Keras
```{r}
library(keras)
#install_keras()
```

Prepare data for Keras
```{r}

mm <- function(x){(x-min(x))/(max(x)-min(x))}
mm(c(100,50,75))


scaled <- nums %>% mutate_all(mm)

keras.data <- cbind(binary.categs,scaled)

keras.train <- as.matrix(keras.data[inp$rand<=8,])
keras.test <- as.matrix(keras.data[inp$rand>8,])



```

```{r}
model <- keras_model_sequential() 
model %>% 
  layer_dense(units = 51, activation = "relu", input_shape = c(21)) %>% 
  layer_dropout(rate = 0.4) %>% 
  layer_dense(units = 10, activation = "relu") %>%
  layer_dropout(rate = 0.3) %>%
  layer_dense(units = 5, activation = "relu") %>%
  layer_dense(units = 1, activation = "sigmoid")

model %>% compile(
  loss = "binary_crossentropy",
  optimizer = optimizer_rmsprop(),
  metrics = c("binary_accuracy")
)

history <- model %>% fit(
  keras.train, y.train, 
  epochs = 200, batch_size = 1000, 
  validation_split = 0.2#,
  #verbose=F,
  #silent=T
)

```




```{r}
model %>% evaluate(keras.test, y.test,verbose = 0)
```

```{r}
pred <-predict(model,keras.test)
auc(y.test,pred)
```

Fischer LDA
```{r}
library(MASS)
wine.lda <- lda(left ~ ., data=train)
pred<-predict(wine.lda,test,method="predictive")[["posterior"]][,"1"]
auc(y.test,pred)

```

Check predictions
```{r}
library(lime)
library(caret)

train$left<-as.numeric(train$left)
train$left<-factor(ifelse(train$left==1,"YES","NO"))
cfit <- caret::train(left ~ ., 
                     data = train, 
                     method = "ranger",
                     trControl = trainControl(classProbs=TRUE)
                     )

pred<-predict(cfit,test,type="prob")
pred[c(1,420),]

auc(test$left,pred[,2])
train$left<-NULL
explainer<-lime(train,cfit)
test$left<-factor(ifelse(test$left==1,"YES","NO"))
to_test<-(test %>% filter(left=="NO"))[1,]
to_test <- test[c(1,420),]


test$left<-train$left<-NULL
to_test$left<-NULL
explanations <- explain(to_test, explainer,n_labels = 1,n_features=9)
to_test$left<-NULL
plot_features(explanations)

```

